{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a trial for onnx to convert tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tf2onnx\n",
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.3'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf2onnx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple MNIST handwritten digit classification using tensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.2204 - acc: 0.9352\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.0978 - acc: 0.9706\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0690 - acc: 0.9789\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0526 - acc: 0.9829\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0433 - acc: 0.9861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2468fd1438>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.0719 - acc: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07194251735692378, 0.9802]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2286372e-06 9.6285795e-08 1.4894309e-06 2.1995955e-04 7.7952559e-13\n",
      " 7.3951538e-09 2.7167164e-11 9.9977666e-01 9.4978347e-08 4.0528519e-07]\n"
     ]
    }
   ],
   "source": [
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the digit is classified as \"7\" in prediction\n"
     ]
    }
   ],
   "source": [
    "print(\"the digit is classified as \\\"%s\\\" in prediction\"%np.argmax(prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_model_path = \"./saved_mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 23:56:07.450877 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "W0903 23:56:07.452551 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "W0903 23:56:07.453497 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0903 23:56:07.454456 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0903 23:56:07.455389 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "W0903 23:56:07.456325 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "W0903 23:56:07.457236 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "W0903 23:56:07.458156 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "W0903 23:56:07.459049 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "W0903 23:56:07.459954 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "W0903 23:56:07.460869 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "W0903 23:56:07.461807 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "W0903 23:56:07.462813 139795298592512 util.py:252] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "W0903 23:56:07.467995 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer\n",
      "W0903 23:56:07.470117 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W0903 23:56:07.472045 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "W0903 23:56:07.473800 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "W0903 23:56:07.475511 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0903 23:56:07.477587 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0903 23:56:07.479510 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "W0903 23:56:07.480997 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "W0903 23:56:07.482127 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "W0903 23:56:07.483254 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "W0903 23:56:07.484364 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "W0903 23:56:07.485495 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "W0903 23:56:07.486629 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "W0903 23:56:07.487750 139795298592512 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "W0903 23:56:07.488747 139795298592512 util.py:252] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "W0903 23:56:08.217050 139795298592512 export_utils.py:182] Export includes no default signature!\n",
      "W0903 23:56:08.610061 139795298592512 export_utils.py:182] Export includes no default signature!\n"
     ]
    }
   ],
   "source": [
    "keras.experimental.export_saved_model(model, saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting .pb model to .onnx and verify the prediction using ONNXRruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#python -m tf2onnx.convert --saved-model ./saved_mnist/ --output ./saved_mnist/saved_model.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_ort = ort.InferenceSession(\"./saved_mnist/saved_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input name flatten_1_input:0\n",
      "input shape [None, 28, 28]\n",
      "input type tensor(float)\n"
     ]
    }
   ],
   "source": [
    "input_name = sess_ort.get_inputs()[0].name\n",
    "print(\"input name\", input_name)\n",
    "input_shape = sess_ort.get_inputs()[0].shape\n",
    "print(\"input shape\", input_shape)\n",
    "input_type = sess_ort.get_inputs()[0].type\n",
    "print(\"input type\", input_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_name dense_3/Softmax:0\n",
      "output shape [None, 10]\n",
      "output type tensor(float)\n"
     ]
    }
   ],
   "source": [
    "output_name = sess_ort.get_outputs()[0].name\n",
    "print(\"output_name\", output_name)\n",
    "output_shape = sess_ort.get_outputs()[0].shape\n",
    "print(\"output shape\", output_shape)\n",
    "output_type = sess_ort.get_outputs()[0].type\n",
    "print(\"output type\", output_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a test sample for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = x_test[0]\n",
    "img = img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=img.reshape(1,28,28)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sess_ort.run([output_name], {input_name: img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the digit is classified as \"7\" in ONNXRruntime\n"
     ]
    }
   ],
   "source": [
    "print(\"the digit is classified as \\\"%s\\\" in ONNXRruntime\"%np.argmax(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envOnnxPy3",
   "language": "python",
   "name": "envonnxpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
